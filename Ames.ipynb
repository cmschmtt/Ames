{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "focused-citizenship",
   "metadata": {},
   "source": [
    "## importz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-maryland",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sorted-environment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set max columns and rows displayed\n",
    "# pd.set_option('display.max_columns', 10000)\n",
    "# pd.set_option('display.max_rows', 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-census",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in files\n",
    "training = pd.read_csv(\"datasets/train.csv\", keep_default_na=False, na_values=[''])\n",
    "testing = pd.read_csv(\"datasets/test.csv\", keep_default_na=False, na_values=[''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ambient-divorce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some correlation but with age-related categories there may be some major collinearity here\n",
    "sns.scatterplot(x=training['MS SubClass'], y=training['SalePrice'], alpha=0.1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indoor-commerce",
   "metadata": {},
   "outputs": [],
   "source": [
    "training['MS Zoning'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-object",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I don't think this will be very useful\n",
    "sns.scatterplot(x=training['Lot Config'], y=training['SalePrice'], alpha=0.1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-memory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definite differences between neighborhoods, worth making dummies for\n",
    "sns.scatterplot(x=training['Neighborhood'], y=training['SalePrice'], alpha=0.1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-canberra",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strong correlation but it isn't very linear - this one may require feature engineering\n",
    "# Also that statistical heaping in early decades is suspicious but probably not too damaging\n",
    "sns.scatterplot(x=training['Year Built'], y=training['SalePrice'], alpha=0.2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-volleyball",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar to above but I don't like the look of that floor at 1950, will drop that year if I use this feature\n",
    "# It almost certainly actually represents '1950 OR BEFORE'\n",
    "sns.scatterplot(x=training['Year Remod/Add'], y=training['SalePrice'], alpha=0.2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-child",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 seems really heavily overreported, maybe to the point where this feature would distort results?\n",
    "sns.scatterplot(x=training['Overall Cond'], y=training['SalePrice'], alpha=0.2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naval-dining",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oooh, that's excellent\n",
    "sns.scatterplot(x=training['Overall Qual'], y=training['SalePrice'], alpha=0.2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-arabic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nice strong linear relationship with square footage, but with a few definite outliers that may need to be pruned\n",
    "sns.scatterplot(x=training['1st Flr SF'], y=training['SalePrice'], alpha=0.2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-citation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Surprised that it looks like new houses aren't much bigger overall, there's a trend upwards but not as strong as I expected\n",
    "sns.scatterplot(x=training['Year Built'], y=training['1st Flr SF'], alpha=0.2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-shadow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Even less trend here. That floor definitely has to go.\n",
    "sns.scatterplot(x=training['Year Remod/Add'], y=training['1st Flr SF'], alpha=0.2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-infrastructure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Still just a weak trend - may be survivorship bias. Those outliers are really throwing things off, though. \n",
    "sns.scatterplot(x=training['Year Built'], y=training['Gr Liv Area'], alpha=0.2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-bunny",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting rid of the outliers\n",
    "training.drop(training[training['Gr Liv Area'] > 4000].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-treaty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting rid of that floor\n",
    "training.drop(training[training['Year Remod/Add'] == 1950].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-promise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MUCH better\n",
    "sns.scatterplot(x=training['Year Remod/Add'], y=training['Gr Liv Area'], alpha=0.2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artificial-cannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fascinating - strong, fairly linear correlation but it seems like more recent builds have a steeper correlation than older ones\n",
    "sns.scatterplot(x=training['Gr Liv Area'], y=training['SalePrice'], hue=training['Year Built'], palette='CMRmap_r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-hunger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is not diverse enough to be useful\n",
    "training['Heating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-junior",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same for this one\n",
    "training['Central Air'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "large-daisy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This could be useful?\n",
    "sns.scatterplot(x=training['Functional'], y=training['SalePrice'], alpha=0.2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-conversion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I actually think it isn't diverse enough or strong enough, I won't use it\n",
    "training['Functional'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-period",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining just the features I want to work with\n",
    "subset = [\n",
    "    'Id', \n",
    "    'Lot Area', \n",
    "    'Neighborhood', \n",
    "    'Overall Qual', \n",
    "    'Overall Cond', \n",
    "    'Year Built', \n",
    "    'Year Remod/Add', \n",
    "    'Bsmt Unf SF', \n",
    "    'Total Bsmt SF', \n",
    "    'Gr Liv Area', \n",
    "    'Bedroom AbvGr', \n",
    "    'Garage Type',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-scientist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smaller dataframe with just my features\n",
    "train_trimmed = training[subset].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filled-murder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gotta add sale price back onto the training set\n",
    "train_trimmed['SalePrice'] = training['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considered-composite",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trimming test too\n",
    "test_trimmed = testing[subset].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "falling-vintage",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trimmed.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-needle",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trimmed.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "touched-castle",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trimmed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-collectible",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nothing untoward here - some very skewed distributions but that's to be expected\n",
    "train_trimmed.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-software",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trimmed['Bedroom AbvGr'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-methodology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Engineering a feature for finished basement square footage\n",
    "train_trimmed['Bsmt Fin SF'] = train_trimmed['Total Bsmt SF'] - train_trimmed['Bsmt Unf SF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agricultural-astrology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeating in test\n",
    "test_trimmed['Bsmt Fin SF'] = test_trimmed['Total Bsmt SF'] - test_trimmed['Bsmt Unf SF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personalized-negotiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trimmed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerous-height",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 is so dominant and spans such a diverse range of prices that I think I won't use Cond\n",
    "train_trimmed['Overall Cond'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floating-flood",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Cond from both frames\n",
    "train_trimmed.drop(columns='Overall Cond', inplace=True)\n",
    "test_trimmed.drop(columns='Overall Cond', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varied-scanner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting dummies for my categoricals\n",
    "train_dummy = pd.get_dummies(data=train_trimmed, columns=['Neighborhood', 'Garage Type'], drop_first=True)\n",
    "test_dummy = pd.get_dummies(data=test_trimmed, columns=['Neighborhood', 'Garage Type'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-piano",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dummy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "institutional-premiere",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see if there are any discrepancies between train and test besides sale price\n",
    "set(train_dummy.columns.tolist()) - set(test_dummy.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stylish-merchant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add those neighborhood dummy columns to test for the sake of consistency\n",
    "test_dummy['Neighborhood_GrnHill'] = 0\n",
    "test_dummy['Neighborhood_Landmrk'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "talented-region",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nothing in test that isn't in train, thankfully\n",
    "set(test_dummy.columns.tolist()) - set(train_dummy.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrapped-southwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up features and target for a quick initial regression\n",
    "X = train_dummy.drop(columns=['Id', 'Total Bsmt SF', 'SalePrice'])\n",
    "X2 = test_dummy.drop(columns=['Id', 'Total Bsmt SF'])\n",
    "y = train_dummy['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "partial-polls",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a linear regression object\n",
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-hawaiian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This looks surprisingly good?\n",
    "cross_val_score(lr, X, y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "destroyed-river",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick fit\n",
    "lr.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "owned-memphis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions and add them to the frame as a new column\n",
    "train_dummy['preds'] = lr.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-prototype",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter residuals against target - I'm overestimating at lower prices and drastically underestimating at high prices\n",
    "# Basically we have a curve here where there ought to be a line. Poly features may help. \n",
    "sns.scatterplot(x=y, y=(train_dummy['preds']-y));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifteen-drove",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, time to get serious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-edition",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train_dummy.drop(columns=['Id', 'Total Bsmt SF', 'SalePrice', 'preds']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outside-directive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate polynomial features\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=False, include_bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scenic-metallic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poly transforming train and test sets\n",
    "X_poly = poly.fit_transform(X)\n",
    "X2_poly = poly.fit_transform(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-azerbaijan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn these poly versions back into dataframes\n",
    "X_poly_df = pd.DataFrame(X_poly, columns=poly.get_feature_names(features))\n",
    "X2_poly_df = pd.DataFrame(X2_poly, columns=poly.get_feature_names(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-throw",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The interactions between neighborhoods are pointless but shouldn't have any effect, so I think it would be more work to get rid of them\n",
    "X_poly_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-potato",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test splits.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_poly_df,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-purchase",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and apply standard scaler\n",
    "sc = StandardScaler()\n",
    "Z_train = sc.fit_transform(X_train)\n",
    "Z_test = sc.transform(X_test)\n",
    "Z_test_2 = sc.transform(X2_poly_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-debate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating and fitting a new linear regression on scaled poly data\n",
    "lr2 = LinearRegression()\n",
    "lr2.fit(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dangerous-rebate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hahahaha oh god what the hell is that test score\n",
    "print(f\"Training data score: {lr2.score(Z_train, y_train)}\")\n",
    "print(f\"Testing data score: {lr2.score(Z_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-demonstration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This looks great\n",
    "sns.scatterplot(x=y_train, y=lr2.predict(Z_train));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bulgarian-celebration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So I think we can say this is a liiiiiiiiittle overfit\n",
    "sns.scatterplot(x=y_test, y=lr2.predict(Z_test));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "public-portal",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train.columns), len(lr2.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-heading",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-carry",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df = pd.DataFrame({\n",
    "    'features': X_train.columns,\n",
    "    'vals': lr2.coef_\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-algorithm",
   "metadata": {},
   "outputs": [],
   "source": [
    "349662.63875770895 % 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serial-award",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2.predict(Z_test).tolist()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspected-principle",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocal-vacation",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sealed-handbook",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
